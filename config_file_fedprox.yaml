common_args:
  training_type: "simulation"
  random_seed: 0
  config_version: "dev"
  mlops_api_key: c9356b9c4ce44363bb66366b210201
  mlops_project_name: simulation_2
  mlops_run_name: fedml_torch_fedavg_mnist_lr_1
  alpha_dirichlet: 0.1
  dirichlet_seed: 2152041540

data_args:
  dataset: "CIFAR10"
  data_cache_dir: ~/.cache/fedml_data
  partition_method: "hetero"
  partition_alpha: 0.5

model_args:
  model: "RESNET_18"

train_args:
  federated_optimizer: "FedProx"
  client_id_list: "[]"
  client_num_in_total: 100
  client_num_per_round: 10
  comm_round: 500 # 3 is for quick GitHub sanity check. please change this to your own hyper-parameters (e.g., 200)
  epochs: 1
  batch_size: 32
  client_optimizer: sgd
  learning_rate: 0.01
  weight_decay: 0.001
  server_optim: false
  server_optimizer: 
  server_lr: 1
  group_norm_size: 0
  fedprox_mu: 0.01

validation_args:
  frequency_of_the_test: 5

device_args:
  using_gpu: true
  gpu_id: 3

comm_args:
  backend: "sp"

tracking_args:
  enable_tracking: False
  enable_wandb: True
  run_name: fedml_torch_fedavg_mnist_lr
  wandb_entity: fedml-ai
  wandb_key: ee0b5f53d949c84cee7decbe7a629e63fb2f8408
  wandb_project: simulation
  resume_wandb: False     # either must or False

